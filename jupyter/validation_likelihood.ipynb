{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow_probability as tfp\n",
    "import sys\n",
    "import scipy.io\n",
    "sys.path.append(\"..\")\n",
    "import ODE_Dynamics as od\n",
    "import Test_Likelihood as tl\n",
    "import Positive_Symptom_fn as fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = scipy.io.loadmat('../data/test_data.mat')\n",
    "x = tf.cast(data['data'],dtype = tf.float32)\n",
    "test_data = np.reshape(\n",
    "      x, x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = tf.transpose(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(25,), dtype=float32, numpy=\n",
       "array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,\n",
       "       13., 14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24.],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[...,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vdyn_ode_fn = od.ViralDynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_fn = fn.proba_pos_sym(3e4).positive_fn\n",
    "symptom_fn = fn.proba_pos_sym(3e4).symptom_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_s_ibar = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "loglike = tl.loglik(test_data, vdyn_ode_fn, positive_fn, symptom_fn, prob_s_ibar, prob_fp=0.0, Epi_Model=od.SIR,\n",
    "                 duration=24.0, Epi_cadence=0.5, Vir_cadence=0.0625)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1053.68214495]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# epipar = tf.constant([\n",
    "#   [[2.2, 3.1E-05,0.8],\n",
    "#    [2.4, 3.6E-05,0.9]],\n",
    "#   [[1.8, 2.6E-05,0.83],\n",
    "#    [1.7, 2.9E-05,0.88]],\n",
    "#   [[2.0, 3.3E-05,0.78],\n",
    "#    [2.2, 3.0E-05,0.75]],])\n",
    "\n",
    "mu_b, sigma_b = 5, 1\n",
    "beta = np.random.normal(mu_b, sigma_b, 1)\n",
    "L = 0.0025/beta\n",
    "V0 = np.random.normal(1E3, 1E2, 1)\n",
    "print(V0)\n",
    "X0 = 1E6\n",
    "Y0 = V0\n",
    "par=tf.constant(np.array([[L,0.01,beta*1E-7,0.5,20,10, V0, X0, Y0]], dtype=np.float32))\n",
    "\n",
    "# par = tf.constant([\n",
    "#   [[5E3,0.01,5E-7,0.5,20,10],\n",
    "#    [5E3,0.01,5E-7,0.5,20,10]],\n",
    "#   [[5E3,0.01,5E-7,0.5,20,10],\n",
    "#    [5E3,0.01,5E-7,0.5,20,10]],\n",
    "#   [[5E3,0.01,5E-7,0.5,20,10],\n",
    "#    [5E3,0.01,5E-7,0.5,20,10]],])\n",
    "vpar = par\n",
    "pospar = par\n",
    "sympar = par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "epipar=tf.constant(np.array([[2.2, 3.6E-05,0.76, 0.001,0.999]], dtype=np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing solution times\n",
      "tf.Tensor(\n",
      "[ 0.      0.0625  0.125   0.1875  0.25    0.3125  0.375   0.4375  0.5\n",
      "  0.5625  0.625   0.6875  0.75    0.8125  0.875   0.9375  1.      1.0625\n",
      "  1.125   1.1875  1.25    1.3125  1.375   1.4375  1.5     1.5625  1.625\n",
      "  1.6875  1.75    1.8125  1.875   1.9375  2.      2.0625  2.125   2.1875\n",
      "  2.25    2.3125  2.375   2.4375  2.5     2.5625  2.625   2.6875  2.75\n",
      "  2.8125  2.875   2.9375  3.      3.0625  3.125   3.1875  3.25    3.3125\n",
      "  3.375   3.4375  3.5     3.5625  3.625   3.6875  3.75    3.8125  3.875\n",
      "  3.9375  4.      4.0625  4.125   4.1875  4.25    4.3125  4.375   4.4375\n",
      "  4.5     4.5625  4.625   4.6875  4.75    4.8125  4.875   4.9375  5.\n",
      "  5.0625  5.125   5.1875  5.25    5.3125  5.375   5.4375  5.5     5.5625\n",
      "  5.625   5.6875  5.75    5.8125  5.875   5.9375  6.      6.0625  6.125\n",
      "  6.1875  6.25    6.3125  6.375   6.4375  6.5     6.5625  6.625   6.6875\n",
      "  6.75    6.8125  6.875   6.9375  7.      7.0625  7.125   7.1875  7.25\n",
      "  7.3125  7.375   7.4375  7.5     7.5625  7.625   7.6875  7.75    7.8125\n",
      "  7.875   7.9375  8.      8.0625  8.125   8.1875  8.25    8.3125  8.375\n",
      "  8.4375  8.5     8.5625  8.625   8.6875  8.75    8.8125  8.875   8.9375\n",
      "  9.      9.0625  9.125   9.1875  9.25    9.3125  9.375   9.4375  9.5\n",
      "  9.5625  9.625   9.6875  9.75    9.8125  9.875   9.9375 10.     10.0625\n",
      " 10.125  10.1875 10.25   10.3125 10.375  10.4375 10.5    10.5625 10.625\n",
      " 10.6875 10.75   10.8125 10.875  10.9375 11.     11.0625 11.125  11.1875\n",
      " 11.25   11.3125 11.375  11.4375 11.5    11.5625 11.625  11.6875 11.75\n",
      " 11.8125 11.875  11.9375 12.     12.0625 12.125  12.1875 12.25   12.3125\n",
      " 12.375  12.4375 12.5    12.5625 12.625  12.6875 12.75   12.8125 12.875\n",
      " 12.9375 13.     13.0625 13.125  13.1875 13.25   13.3125 13.375  13.4375\n",
      " 13.5    13.5625 13.625  13.6875 13.75   13.8125 13.875  13.9375 14.\n",
      " 14.0625 14.125  14.1875 14.25   14.3125 14.375  14.4375 14.5    14.5625\n",
      " 14.625  14.6875 14.75   14.8125 14.875  14.9375 15.     15.0625 15.125\n",
      " 15.1875 15.25   15.3125 15.375  15.4375 15.5    15.5625 15.625  15.6875\n",
      " 15.75   15.8125 15.875  15.9375 16.     16.0625 16.125  16.1875 16.25\n",
      " 16.3125 16.375  16.4375 16.5    16.5625 16.625  16.6875 16.75   16.8125\n",
      " 16.875  16.9375 17.     17.0625 17.125  17.1875 17.25   17.3125 17.375\n",
      " 17.4375 17.5    17.5625 17.625  17.6875 17.75   17.8125 17.875  17.9375\n",
      " 18.     18.0625 18.125  18.1875 18.25   18.3125 18.375  18.4375 18.5\n",
      " 18.5625 18.625  18.6875 18.75   18.8125 18.875  18.9375 19.     19.0625\n",
      " 19.125  19.1875 19.25   19.3125 19.375  19.4375 19.5    19.5625 19.625\n",
      " 19.6875 19.75   19.8125 19.875  19.9375 20.     20.0625 20.125  20.1875\n",
      " 20.25   20.3125 20.375  20.4375 20.5    20.5625 20.625  20.6875 20.75\n",
      " 20.8125 20.875  20.9375 21.     21.0625 21.125  21.1875 21.25   21.3125\n",
      " 21.375  21.4375 21.5    21.5625 21.625  21.6875 21.75   21.8125 21.875\n",
      " 21.9375 22.     22.0625 22.125  22.1875 22.25   22.3125 22.375  22.4375\n",
      " 22.5    22.5625 22.625  22.6875 22.75   22.8125 22.875  22.9375 23.\n",
      " 23.0625 23.125  23.1875 23.25   23.3125 23.375  23.4375 23.5    23.5625\n",
      " 23.625  23.6875 23.75   23.8125 23.875  23.9375], shape=(384,), dtype=float32)\n",
      "printing initial time\n",
      "0.0\n",
      "printing initial state\n",
      "tf.Tensor([[   1053.6821 1000000.        1053.6821]], shape=(1, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[  1053.6821   1515.4316   1769.0421   1925.6522   2034.8021   2122.6543\n",
      "    2197.8237   2272.919    2346.0225   2418.871    2495.6326   2574.0754\n",
      "    2652.3225   2731.3948   2815.1335   2904.289    2994.33     3083.878\n",
      "    3175.0334   3272.882    3375.8782   3479.0537   3581.802    3687.7385\n",
      "    3802.399    3920.8733   4038.5715   4156.0454   4278.884    4412.1294\n",
      "    4547.9053   4682.311    4817.5615   4961.762    5115.935    5270.734\n",
      "    5423.4326   5578.4824   5746.3896   5923.544    6099.8623   6274.289\n",
      "    6454.3784   6650.9355   6853.446    7052.996    7250.9355   7458.6997\n",
      "    7685.949    7916.573    8143.2007   8370.551    8615.087    8880.867\n",
      "    9145.127    9398.33     9648.334    9920.394   10223.624   10525.148\n",
      "   10818.701   11119.408   11448.535   11785.164   12115.999   12444.967\n",
      "   12792.874   13170.714   13551.23    13924.071   14298.846   14704.368\n",
      "   15144.404   15578.869   15992.057   16398.793   16844.441   17342.658\n",
      "   17835.547   18313.105   18802.744   19338.809   19884.139   20418.873\n",
      "   20951.205   21516.693   22126.646   22737.29    23333.57    23932.678\n",
      "   24580.95    25269.262   25950.283   26615.361   27293.514   28042.176\n",
      "   28832.322   29595.105   30316.832   31041.062   31862.363   32745.188\n",
      "   33602.312   34433.46    35307.344   36253.42    37197.734   38117.066\n",
      "   39039.09    40036.29    41090.91    42129.504   43138.21    44161.766\n",
      "   45284.047   46450.355   47588.18    48696.305   49841.363   51116.363\n",
      "   52425.746   53667.1     54837.426   56033.316   57413.547   58848.438\n",
      "   60220.562   61552.03    62976.996   64497.574   65991.98    67433.19\n",
      "   68882.23    70465.336   72115.67    73717.6     75259.96    76831.61\n",
      "   78565.91    80340.08    82045.22    83690.47    85398.65    87313.59\n",
      "   89251.95    91053.1     92722.41    94431.14    96436.57    98496.086\n",
      "  100428.83   102278.055  104267.54   106387.     108440.61   110387.336\n",
      "  112326.08   114457.2    116670.16   118782.21   120772.984  122777.23\n",
      "  125010.51   127291.47   129443.08   131470.22   133550.61   135912.69\n",
      "  138300.88   140465.8    142398.4    144329.75   146652.23   149068.6\n",
      "  151278.77   153314.64   155477.72   157837.75   160093.27   162154.03\n",
      "  164127.75   166301.62   168625.39   170803.52   172765.78   174656.2\n",
      "  176790.72   179035.36   181095.67   182924.61   184705.27   186796.39\n",
      "  189030.22   190987.     192558.25   193957.83   195714.83   197799.2\n",
      "  199639.72   201157.58   202631.67   204415.95   206139.89   207599.61\n",
      "  208842.77   210161.44   211756.4    213239.9    214431.27   215404.02\n",
      "  216485.56   217847.56   219070.27   219989.45   220705.9    221583.52\n",
      "  222786.36   223816.98   224409.75   224646.03   224954.23   225820.28\n",
      "  226614.45   227038.28   227207.42   227579.75   228114.08   228428.97\n",
      "  228436.56   228307.47   228432.56   228685.92   228706.23   228420.98\n",
      "  228019.77   227897.31   227877.56   227612.33   227042.7    226374.36\n",
      "  226007.02   225727.69   225197.77   224371.1    223467.47   222907.56\n",
      "  222501.75   221789.44   220644.73   219283.61   218262.42   217644.39\n",
      "  216796.77   215601.56   214294.66   213310.44   212356.47   211163.05\n",
      "  209724.58   208276.3    207186.1    206180.72   204872.73   203183.77\n",
      "  201345.06   199889.06   198762.36   197417.67   195779.66   194090.03\n",
      "  192707.06   191322.67   189730.66   187945.89   186192.36   184731.42\n",
      "  183264.25   181596.92   179745.7    177929.8    176406.83   174883.2\n",
      "  173170.86   171286.47   169443.52   167925.03   166458.02   164750.72\n",
      "  162760.61   160693.3    158986.12   157520.16   155887.12   154043.05\n",
      "  152192.34   150603.25   149018.22   147285.38   145422.16   143607.67\n",
      "  142036.34   140469.31   138762.56   136930.69   135142.53   133593.52\n",
      "  132059.02   130396.25   128616.78   126879.51   125397.57   123970.43\n",
      "  122380.78   120594.016  118757.086  117189.45   115821.805  114347.45\n",
      "  112728.39   111105.67   109683.86   108285.414  106792.26   105209.92\n",
      "  103660.17   102296.875  100959.484   99534.64    98024.266   96540.03\n",
      "   95234.1     93961.44    92609.66    91177.25    89766.44    88538.516\n",
      "   87380.12    86123.97    84731.04    83290.03    82017.04    80927.625\n",
      "   79781.09    78535.22    77272.48    76149.766   75068.11    73931.85\n",
      "   72734.35    71548.625   70491.72    69475.78    68410.16    67285.5\n",
      "   66166.984   65168.37    64217.117   63222.574   62172.984   61126.574\n",
      "   60196.18    59338.48    58430.445   57432.438   56389.92    55433.42\n",
      "   54631.87    53809.496   52922.87    52012.676   51186.812   50409.74\n",
      "   49605.09    48758.87    47909.78    47139.668   46417.58    45671.625\n",
      "   44886.26    44095.086   43374.86    42704.855   42014.94    41288.277 ]], shape=(1, 384), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]], shape=(1, 384), dtype=float32)\n",
      "Printing probas\n",
      "tf.Tensor(0.00037295918, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00037277464, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "ll = loglike.__call__(test_data,epipar, vpar, pospar, sympar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=-20375.475>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ll"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
