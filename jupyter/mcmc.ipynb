{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import sys\n",
    "import math\n",
    "import scipy.io\n",
    "sys.path.append(\"..\")\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "#tf.enable_v2_behavior()\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "import Test_Likelihood as tl\n",
    "import ODE_Dynamics as od\n",
    "import Positive_Symptom_fn as fn\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "import scipy.stats as ss\n",
    "\n",
    "import simulation as sim\n",
    "import model as mdl\n",
    "\n",
    "tfd = tfp.distributions\n",
    "tfb = tfp.bijectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "[[1032    1]\n",
      " [1039    1]\n",
      " [ 985    1]\n",
      " [1034    5]\n",
      " [ 965    4]\n",
      " [ 967    5]\n",
      " [ 993    4]\n",
      " [ 960    4]\n",
      " [1046    7]\n",
      " [ 973    5]]\n"
     ]
    }
   ],
   "source": [
    "vload = sim.sample_viral_load(mu_b = 12,sigma_b = 1)\n",
    "prob_s_i0 = 0.55; prob_s_ibar0 = 0.1\n",
    "p_threshold0 = 170306.4 * 1E-05\n",
    "s_threshold0 = sim.get_symptom_threshold(vload)\n",
    "start_day0 = 20\n",
    "full_data = sim.simulate_epidemic(vload, pop_size = 10000, start_day = start_day0,\n",
    "                             prob_s_i = prob_s_i0, prob_s_ibar = prob_s_ibar0, \n",
    "                             v_threshold = p_threshold0)\n",
    "start_day = 0\n",
    "end_day = 10\n",
    "sliced_data = full_data[start_day:end_day,:]\n",
    "print(sliced_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.000e+00 1.032e+03 1.000e+00]\n",
      " [1.000e+00 1.039e+03 1.000e+00]\n",
      " [2.000e+00 9.850e+02 1.000e+00]\n",
      " [3.000e+00 1.034e+03 5.000e+00]\n",
      " [4.000e+00 9.650e+02 4.000e+00]\n",
      " [5.000e+00 9.670e+02 5.000e+00]\n",
      " [6.000e+00 9.930e+02 4.000e+00]\n",
      " [7.000e+00 9.600e+02 4.000e+00]\n",
      " [8.000e+00 1.046e+03 7.000e+00]\n",
      " [9.000e+00 9.730e+02 5.000e+00]], shape=(10, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Arrange data in workable format\n",
    "days = [float(i) for i in list(range(len(sliced_data)))]\n",
    "tests = sliced_data[:,0]\n",
    "positives = sliced_data[:,1]\n",
    "test_data = np.column_stack((days, tests, positives))\n",
    "test_data = tf.cast(test_data, dtype = tf.float32)\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 9)\n"
     ]
    }
   ],
   "source": [
    "vdyn_ode_fn = od.ViralDynamics\n",
    "positive_fn = fn.proba_pos_sym(p_threshold0).positive_fn\n",
    "symptom_fn = fn.proba_pos_sym(p_threshold0).symptom_fn\n",
    "prob_s_ibar = prob_s_ibar0\n",
    "sample_size = 1000\n",
    "k = 1\n",
    "index = 1\n",
    "mu_b, sigma_b = 12, 1\n",
    "beta = np.random.normal(mu_b, sigma_b, 1)   #\"rate at which virus infects host cells\"\n",
    "L = 0.0025/beta\n",
    "\n",
    "V0 = np.random.normal(1E3, 1E2, 1)\n",
    "X0 = 1E6\n",
    "Y0 = V0\n",
    "\n",
    "par=np.array([[L,0.01,beta*1E-7,0.5,20.0,10.0,V0,X0,Y0]])\n",
    "\n",
    "init_state=(np.array([[V0,X0,Y0]], dtype=np.float32))\n",
    "\n",
    "while index <= sample_size - 1:\n",
    "    beta = np.random.normal(mu_b, sigma_b, 1)   #\"rate at which virus infects host cells\"\n",
    "    L = 0.0025/beta\n",
    "    \n",
    "    V0 = np.random.normal(1E3, 1E2, 1)\n",
    "    X0 = 1E6\n",
    "    Y0 = V0\n",
    "    \n",
    "    par_new=np.array([[L,0.01,beta*1E-7,0.5,20.0,10.0,V0,X0,Y0]])\n",
    "    par = np.concatenate((par, par_new), axis = 0)\n",
    "    \n",
    "    init_state_new=(np.array([[V0,X0,Y0]], dtype=np.float32))\n",
    "    init_state = np.concatenate((init_state, init_state_new), 0)\n",
    "\n",
    "    index +=1\n",
    "        \n",
    "\n",
    "vpar = tf.constant(par, dtype=tf.float32)\n",
    "pospar = par\n",
    "sympar = par\n",
    "print(par.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joint prior on nu, i, s\n",
    "# nu ~ Beta(2,8), so that mode = 0.1\n",
    "# i, s, (1-i-s) ~ Dirichlet(0.1,0.1,0.1)\n",
    "\n",
    "joint_prior = tfd.JointDistributionNamed(dict(\n",
    "    recov_rate = tfd.Beta(2,8),\n",
    "    epi_state = tfd.Dirichlet(\n",
    "    concentration = np.ones(3, np.float32)/10),\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joint log prior\n",
    "def joint_log_prior(R0, nu, epi_state):\n",
    "    #epi_state = [i, s]\n",
    "    return joint_prior.log_prob(\n",
    "      recov_rate = nu, epi_state = epi_state)- math.log(R0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joint log-likelihood\n",
    "# Prior on R0: 1/R0\n",
    "\n",
    "def joint_log_prob(test_data, R0, nu, epi_state):\n",
    "    epi_state = np.array(epi_state)\n",
    "    i = epi_state[...,0]\n",
    "    s = epi_state[...,1]\n",
    "    epipar = tf.constant(np.array([[R0, 5.0E-08, nu, i, s]], dtype=np.float32))\n",
    "\n",
    "    loglike = mdl.loglik(test_data, vdyn_ode_fn, positive_fn, symptom_fn, prob_s_ibar = 0.1, prob_fp=0.0, Epi_Model=od.SIR,\n",
    "                 duration= start_day0, Epi_cadence = 0.5, Vir_cadence = 0.0675, phi_s = 0.55, psi_s = 0.1)\n",
    "    ll,pp = loglike.__call__(test_data, epipar, vpar, pospar, sympar)\n",
    "    #r = 1.0-i-s\n",
    "    ll = ll + joint_log_prior(R0, nu, epi_state).numpy()\n",
    "    return sum(ll)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial time\n",
      "tf.Tensor(-21.0, shape=(), dtype=float32)\n",
      "final time\n",
      "tf.Tensor(10.0, shape=(), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=-4336.4336>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joint_log_prob(test_data, R0 = 1.8, nu = 0.1, epi_state = [0.01,0.9,0.09])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute log_lik \n",
    "# Impute things we don't want to sample, eg. observations\n",
    "\n",
    "unnormalized_posterior_log_prob = partial(joint_log_prob, test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "initial_state = [tf.convert_to_tensor(R0, dtype = tf.float32), tf.convert_to_tensor(nu0,dtype = tf.float32), tf.convert_to_tensor([i0, s0, r0], dtype = tf.float32)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform all parameters so that parameter spaces are unconstrained\n",
    "# Every parameter needs a bijector, might be 'Identity'\n",
    "\n",
    "unconstraining_bijectors = [\n",
    "    tfb.Log(),\n",
    "    tfb.Sigmoid(),\n",
    "    tfb.SoftmaxCentered()  \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sample = 10000\n",
    "n_burnin = 6000\n",
    "n_adaptation = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@tf.function(autograph=False)\n",
    "def sample():\n",
    "    return tfp.mcmc.sample_chain(\n",
    "        num_results = n_sample,\n",
    "        num_burnin_steps = n_burnin,\n",
    "        current_state = initial_state,\n",
    "        kernel = tfp.mcmc.SimpleStepSizeAdaptation(\n",
    "            tfp.mcmc.TransformedTransitionKernel(\n",
    "                inner_kernel = tfp.mcmc.HamiltonianMonteCarlo(\n",
    "                    target_log_prob_fn = unnormalized_posterior_log_prob,\n",
    "                     step_size = 0.01,\n",
    "                     num_leapfrog_steps = 2),\n",
    "                bijector = unconstraining_bijectors),\n",
    "             num_adaptation_steps = n_adaptation),\n",
    "        trace_fn=lambda _, pkr: pkr.inner_results.inner_results.is_accepted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial time\n",
      "tf.Tensor(-21.0, shape=(), dtype=float32)\n",
      "final time\n",
      "tf.Tensor(10.0, shape=(), dtype=float32)\n",
      "initial time\n",
      "tf.Tensor(-21.0, shape=(), dtype=float32)\n",
      "final time\n",
      "tf.Tensor(10.0, shape=(), dtype=float32)\n",
      "initial time\n",
      "tf.Tensor(-21.0, shape=(), dtype=float32)\n",
      "final time\n",
      "tf.Tensor(10.0, shape=(), dtype=float32)\n",
      "initial time\n",
      "tf.Tensor(-21.0, shape=(), dtype=float32)\n",
      "final time\n",
      "tf.Tensor(10.0, shape=(), dtype=float32)\n",
      "initial time\n",
      "tf.Tensor(-21.0, shape=(), dtype=float32)\n",
      "final time\n",
      "tf.Tensor(10.0, shape=(), dtype=float32)\n",
      "initial time\n",
      "tf.Tensor(-21.0, shape=(), dtype=float32)\n",
      "final time\n",
      "tf.Tensor(10.0, shape=(), dtype=float32)\n",
      "initial time\n",
      "tf.Tensor(-21.0, shape=(), dtype=float32)\n",
      "final time\n",
      "tf.Tensor(10.0, shape=(), dtype=float32)\n",
      "initial time\n",
      "tf.Tensor(-21.0, shape=(), dtype=float32)\n",
      "final time\n",
      "tf.Tensor(10.0, shape=(), dtype=float32)\n",
      "initial time\n",
      "tf.Tensor(-21.0, shape=(), dtype=float32)\n",
      "final time\n",
      "tf.Tensor(10.0, shape=(), dtype=float32)\n",
      "initial time\n",
      "tf.Tensor(-21.0, shape=(), dtype=float32)\n",
      "final time\n",
      "tf.Tensor(10.0, shape=(), dtype=float32)\n",
      "initial time\n",
      "tf.Tensor(-21.0, shape=(), dtype=float32)\n",
      "final time\n",
      "tf.Tensor(10.0, shape=(), dtype=float32)\n",
      "initial time\n",
      "tf.Tensor(-21.0, shape=(), dtype=float32)\n",
      "final time\n",
      "tf.Tensor(10.0, shape=(), dtype=float32)\n",
      "initial time\n",
      "tf.Tensor(-21.0, shape=(), dtype=float32)\n",
      "final time\n",
      "tf.Tensor(10.0, shape=(), dtype=float32)\n",
      "initial time\n",
      "tf.Tensor(-21.0, shape=(), dtype=float32)\n",
      "final time\n",
      "tf.Tensor(10.0, shape=(), dtype=float32)\n",
      "initial time\n",
      "tf.Tensor(-21.0, shape=(), dtype=float32)\n",
      "final time\n",
      "tf.Tensor(10.0, shape=(), dtype=float32)\n",
      "initial time\n",
      "tf.Tensor(-21.0, shape=(), dtype=float32)\n",
      "final time\n",
      "tf.Tensor(10.0, shape=(), dtype=float32)\n",
      "initial time\n",
      "tf.Tensor(-21.0, shape=(), dtype=float32)\n",
      "final time\n",
      "tf.Tensor(10.0, shape=(), dtype=float32)\n",
      "initial time\n",
      "tf.Tensor(-21.0, shape=(), dtype=float32)\n",
      "final time\n",
      "tf.Tensor(10.0, shape=(), dtype=float32)\n",
      "initial time\n",
      "tf.Tensor(-21.0, shape=(), dtype=float32)\n",
      "final time\n",
      "tf.Tensor(10.0, shape=(), dtype=float32)\n",
      "initial time\n",
      "tf.Tensor(-21.0, shape=(), dtype=float32)\n",
      "final time\n",
      "tf.Tensor(10.0, shape=(), dtype=float32)\n",
      "initial time\n",
      "tf.Tensor(-21.0, shape=(), dtype=float32)\n",
      "final time\n",
      "tf.Tensor(10.0, shape=(), dtype=float32)\n",
      "initial time\n",
      "tf.Tensor(-21.0, shape=(), dtype=float32)\n",
      "final time\n",
      "tf.Tensor(10.0, shape=(), dtype=float32)\n",
      "initial time\n",
      "tf.Tensor(-21.0, shape=(), dtype=float32)\n",
      "final time\n",
      "tf.Tensor(10.0, shape=(), dtype=float32)\n",
      "initial time\n",
      "tf.Tensor(-21.0, shape=(), dtype=float32)\n",
      "final time\n",
      "tf.Tensor(10.0, shape=(), dtype=float32)\n",
      "initial time\n",
      "tf.Tensor(-21.0, shape=(), dtype=float32)\n",
      "final time\n",
      "tf.Tensor(10.0, shape=(), dtype=float32)\n",
      "initial time\n",
      "tf.Tensor(-21.0, shape=(), dtype=float32)\n",
      "final time\n",
      "tf.Tensor(10.0, shape=(), dtype=float32)\n",
      "initial time\n",
      "tf.Tensor(-21.0, shape=(), dtype=float32)\n",
      "final time\n",
      "tf.Tensor(10.0, shape=(), dtype=float32)\n",
      "initial time\n",
      "tf.Tensor(-21.0, shape=(), dtype=float32)\n",
      "final time\n",
      "tf.Tensor(10.0, shape=(), dtype=float32)\n",
      "initial time\n",
      "tf.Tensor(-21.0, shape=(), dtype=float32)\n",
      "final time\n",
      "tf.Tensor(10.0, shape=(), dtype=float32)\n",
      "initial time\n",
      "tf.Tensor(-21.0, shape=(), dtype=float32)\n",
      "final time\n",
      "tf.Tensor(10.0, shape=(), dtype=float32)\n",
      "initial time\n",
      "tf.Tensor(-21.0, shape=(), dtype=float32)\n",
      "final time\n",
      "tf.Tensor(10.0, shape=(), dtype=float32)\n",
      "initial time\n",
      "tf.Tensor(-21.0, shape=(), dtype=float32)\n",
      "final time\n",
      "tf.Tensor(10.0, shape=(), dtype=float32)\n",
      "initial time\n",
      "tf.Tensor(-21.0, shape=(), dtype=float32)\n",
      "final time\n",
      "tf.Tensor(10.0, shape=(), dtype=float32)\n",
      "initial time\n",
      "tf.Tensor(-21.0, shape=(), dtype=float32)\n",
      "final time\n",
      "tf.Tensor(10.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "[R0, nu, epi_state], is_accepted = sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute posterior means of Epidemic parameters\n",
    "\n",
    "acceptance_rate = tf.reduce_mean(tf.cast(is_accepted, dtype=tf.float32)).numpy()\n",
    "mean_R0 = tf.reduce_mean(R0, axis=0).numpy()\n",
    "mean_nu = tf.reduce_mean(nu, axis=0).numpy()\n",
    "i_s = np.array(epi_state)\n",
    "i = i_s[...,0]\n",
    "s = i_s[...,1]\n",
    "r = i_s[...,2]\n",
    "mean_i = tf.reduce_mean(i, axis=0).numpy()\n",
    "mean_s = tf.reduce_mean(s, axis=0).numpy()\n",
    "mean_r = tf.reduce_mean(r, axis=0).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acceptance_rate: 0.6\n",
      "avg basic reproduction number: 1.7951206\n",
      "avg recovery rate: 0.09873719\n",
      "avg infected 0.0009731812\n",
      "avg susceptible 0.98960924\n",
      "avg recovered 0.009417571\n"
     ]
    }
   ],
   "source": [
    "print('acceptance_rate:', acceptance_rate)\n",
    "print('avg basic reproduction number:', mean_R0)\n",
    "print('avg recovery rate:', mean_nu)\n",
    "print('avg infected', mean_i)\n",
    "print('avg susceptible', mean_s)\n",
    "print('avg recovered', mean_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecast Infection Rate, 7 Days into Future\n",
    "forecast_window = 7\n",
    "R0_sample = R0[n_burnin:n_sample]\n",
    "nu_sample = nu[n_burnin:n_sample]\n",
    "i_sample = i[n_burnin:n_sample]\n",
    "s_sample = s[n_burnin:n_sample]\n",
    "\n",
    "mod = od.SIR(par)\n",
    "\n",
    "par=tf.constant(np.array([[R0_sample[1].numpy(), 5.0E-08, nu_sample[1].numpy()]], dtype=np.float32))\n",
    "init_state=tf.constant(np.array([[i_sample[1].numpy(),s_sample[1].numpy()]], dtype=np.float32))\n",
    "init_time=tf.constant(0.0)\n",
    "int_duration = end_day - start_day + forecast_window\n",
    "soln_times=tf.constant(np.linspace(0.0,int_duration,num=int_duration,dtype=np.float32))\n",
    "dp = tfp.math.ode.DormandPrince()\n",
    "results = dp.solve(mod.RHS, init_time, init_state, solution_times=soln_times)\n",
    "i_forecast = results.states[:,0,0].numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = 1\n",
    "while id < len(R0_sample):\n",
    "    par=tf.constant(np.array([[R0_sample[id].numpy(), 5.0E-08, nu_sample[id].numpy()]], dtype=np.float32))\n",
    "    init_state=tf.constant(np.array([[i_sample[id].numpy(),s_sample[id].numpy()]], dtype=np.float32))\n",
    "    init_time=tf.constant(0.0)\n",
    "    soln_times=tf.constant(np.linspace(0.0,int_duration,num=int_duration,dtype=np.float32))\n",
    "    dp = tfp.math.ode.DormandPrince()\n",
    "    results = dp.solve(mod.RHS, init_time, init_state, solution_times=soln_times)\n",
    "    i_forecast = np.column_stack((i_forecast, results.states[:,0,0].numpy()))\n",
    "    id += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_forecast_lower = []\n",
    "i_forecast_upper = []\n",
    "i_forecast_median = []\n",
    "\n",
    "for j in range(forecast_window):\n",
    "    id = end_day - start_day + j\n",
    "    i_forecast_lower.append(np.percentile(i_forecast[id], 5))\n",
    "    i_forecast_upper.append(np.percentile(i_forecast[id], 95))\n",
    "    i_forecast_median.append(np.percentile(i_forecast[id], 50))\n",
    "    \n",
    "print(i_forecast_lower)\n",
    "print(i_forecast_upper)\n",
    "print(i_forecast_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par=tf.constant(np.array([[1.8, 5.0E-08,0.1]], dtype=np.float32))\n",
    "mod = od.SIR(par)\n",
    "init_state=tf.constant(np.array([[0.001,0.999]], dtype=np.float32))\n",
    "init_time=tf.constant(0.0)\n",
    "soln_times=tf.constant(np.linspace(0.0,100.0,num=100,dtype=np.float32))\n",
    "dp = tfp.math.ode.DormandPrince()\n",
    "results = dp.solve(mod.RHS, init_time, init_state, solution_times=soln_times)\n",
    "i_true = results.states[:,0,0].numpy()\n",
    "t1 = end_day\n",
    "t2 = end_day + 7\n",
    "i_true = i_true[t1:t2]\n",
    "print(i_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "t = list(range(len(i_forecast_median)))\n",
    "plt.plot(t, i_forecast_lower, \"b--\",label = \"95-th percentile\")\n",
    "plt.plot(t, i_forecast_upper,\"b--\",label = \"5-th percentile\")\n",
    "plt.plot(t, i_forecast_median, \"b-\",label = \"Forecasted Median\")\n",
    "plt.plot(t, i_true, \"r-\", label = \"True Infected\")\n",
    "plt.title('Forecast Confidence Interval')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.savefig('Forecast.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Staircase Plot\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import staircase as sc\n",
    "inverse_data = np.column_stack((R0_sample.numpy(), nu_sample.numpy(), i_sample.numpy(), s_sample.numpy()))\n",
    "figname = \"mcmc_staircase.png\"\n",
    "ndim = 4\n",
    "scales = [0,0,0,0]\n",
    "scales[0] = (min(R0_sample),max(R0_sample))\n",
    "scales[1] = (min(nu_sample),max(nu_sample))\n",
    "scales[2] = (min(i_sample),max(i_sample))\n",
    "scales[3] = (min(s_sample),max(s_sample))\n",
    "\n",
    "bin_num = 10\n",
    "axlabel = [\"R0\", \"nu\", \"i\", \"s\"]\n",
    "#sc.staircase_plot(inverse_data, figname, hist_scalex, hist_scaley, bin_num, xtrue = [1,1,-2,-1,1])\n",
    "sc.staircase_plot_simple(inverse_data, figname, ndim, scales, bin_num, axlabel)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot MCMC evolution\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "fig, axs = plt.subplots(2, 2)\n",
    "t = list(range(len(s)))\n",
    "axs[0, 0].plot(t, R0.numpy(), \"b-\")\n",
    "axs[0, 0].set_title('R0')\n",
    "axs[0, 1].plot(t, nu.numpy(), \"b-\")\n",
    "axs[0, 1].set_title('nu')\n",
    "axs[1, 0].plot(t, i.numpy(), \"b-\")\n",
    "axs[1, 0].set_title('i')\n",
    "axs[1, 1].plot(t, s.numpy(), \"b-\")\n",
    "axs[1, 1].set_title('s')\n",
    "\n",
    "for ax in axs.flat:\n",
    "    ax.set(xlabel='MCMC draws', ylabel='Time')\n",
    "\n",
    "# Hide x labels and tick labels for top plots and y ticks for right plots.\n",
    "for ax in axs.flat:\n",
    "    ax.label_outer()\n",
    "    \n",
    "plt.savefig('MCMC_runs.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
