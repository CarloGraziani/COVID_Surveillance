{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import sys\n",
    "import math\n",
    "import scipy.io\n",
    "sys.path.append(\"..\")\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow.compat.v2 as tf\n",
    "tf.enable_v2_behavior()\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "import Test_Likelihood as tl\n",
    "import ODE_Dynamics as od\n",
    "import Positive_Symptom_fn as fn\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "import scipy.stats as ss\n",
    "\n",
    "import simulation as sim\n",
    "import model as mdl\n",
    "\n",
    "tfd = tfp.distributions\n",
    "tfb = tfp.bijectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "[[ 978    1]\n",
      " [ 950    3]\n",
      " [ 971    2]\n",
      " [ 998    6]\n",
      " [ 901    3]\n",
      " [ 991    6]\n",
      " [1003    3]\n",
      " [1059    2]\n",
      " [1030    6]\n",
      " [ 960    4]]\n"
     ]
    }
   ],
   "source": [
    "vload = sim.sample_viral_load(mu_b = 12,sigma_b = 1)\n",
    "prob_s_i0 = 0.55; prob_s_ibar0 = 0.1\n",
    "p_threshold0 = 170306.4 * 1E-05\n",
    "s_threshold0 = sim.get_symptom_threshold(vload)\n",
    "start_day0 = 20\n",
    "full_data = sim.simulate_epidemic(vload, pop_size = 10000, start_day = start_day0,\n",
    "                             prob_s_i = prob_s_i0, prob_s_ibar = prob_s_ibar0, \n",
    "                             v_threshold = p_threshold0)\n",
    "start_day = 0\n",
    "end_day = 10\n",
    "sliced_data = full_data[start_day:end_day,:]\n",
    "print(sliced_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.000e+00 9.780e+02 1.000e+00]\n",
      " [1.000e+00 9.500e+02 3.000e+00]\n",
      " [2.000e+00 9.710e+02 2.000e+00]\n",
      " [3.000e+00 9.980e+02 6.000e+00]\n",
      " [4.000e+00 9.010e+02 3.000e+00]\n",
      " [5.000e+00 9.910e+02 6.000e+00]\n",
      " [6.000e+00 1.003e+03 3.000e+00]\n",
      " [7.000e+00 1.059e+03 2.000e+00]\n",
      " [8.000e+00 1.030e+03 6.000e+00]\n",
      " [9.000e+00 9.600e+02 4.000e+00]], shape=(10, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Arrange data in workable format\n",
    "days = [float(i) for i in list(range(len(sliced_data)))]\n",
    "tests = sliced_data[:,0]\n",
    "positives = sliced_data[:,1]\n",
    "test_data = np.column_stack((days, tests, positives))\n",
    "test_data = tf.cast(test_data, dtype = tf.float32)\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 9)\n"
     ]
    }
   ],
   "source": [
    "vdyn_ode_fn = od.ViralDynamics\n",
    "positive_fn = fn.proba_pos_sym(p_threshold0).positive_fn\n",
    "symptom_fn = fn.proba_pos_sym(p_threshold0).symptom_fn\n",
    "prob_s_ibar = prob_s_ibar0\n",
    "sample_size = 1000\n",
    "k = 1\n",
    "index = 1\n",
    "mu_b, sigma_b = 12, 1\n",
    "beta = np.random.normal(mu_b, sigma_b, 1)   #\"rate at which virus infects host cells\"\n",
    "L = 0.0025/beta\n",
    "\n",
    "V0 = np.random.normal(1E3, 1E2, 1)\n",
    "X0 = 1E6\n",
    "Y0 = V0\n",
    "\n",
    "par=np.array([[L,0.01,beta*1E-7,0.5,20.0,10.0,V0,X0,Y0]])\n",
    "\n",
    "init_state=(np.array([[V0,X0,Y0]], dtype=np.float32))\n",
    "\n",
    "while index <= sample_size - 1:\n",
    "    beta = np.random.normal(mu_b, sigma_b, 1)   #\"rate at which virus infects host cells\"\n",
    "    L = 0.0025/beta\n",
    "    \n",
    "    V0 = np.random.normal(1E3, 1E2, 1)\n",
    "    X0 = 1E6\n",
    "    Y0 = V0\n",
    "    \n",
    "    par_new=np.array([[L,0.01,beta*1E-7,0.5,20.0,10.0,V0,X0,Y0]])\n",
    "    par = np.concatenate((par, par_new), axis = 0)\n",
    "    \n",
    "    init_state_new=(np.array([[V0,X0,Y0]], dtype=np.float32))\n",
    "    init_state = np.concatenate((init_state, init_state_new), 0)\n",
    "\n",
    "    index +=1\n",
    "        \n",
    "\n",
    "vpar = tf.constant(par, dtype=tf.float32)\n",
    "pospar = par\n",
    "sympar = par\n",
    "print(par.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joint prior on nu, i, s\n",
    "# nu ~ Beta(2,8), so that mode = 0.1\n",
    "# i, s, (1-i-s) ~ Dirichlet(0.1,0.1,0.1)\n",
    "\n",
    "joint_prior = tfd.JointDistributionNamed(dict(\n",
    "    recov_rate = tfd.Beta(2,8),\n",
    "    epi_state = tfd.Dirichlet(\n",
    "    concentration = np.ones(3, np.float32)/10),\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joint log prior\n",
    "def joint_log_prior(R0, nu, epi_state):\n",
    "    epi_state = np.array(epi_state)\n",
    "    return joint_prior.log_prob(\n",
    "      recov_rate = nu, epi_state = epi_state)- math.log(R0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joint log-likelihood\n",
    "# Prior on R0: 1/R0\n",
    "\n",
    "def joint_log_prob(test_data, R0, nu, epi_state):\n",
    "    epi_state = np.array(epi_state)\n",
    "    i = epi_state[...,0]\n",
    "    s = epi_state[...,1]\n",
    "    epipar = tf.constant(np.array([[R0, 5.0E-08, nu, i, s]], dtype=np.float32))\n",
    "\n",
    "    loglike = mdl.loglik(test_data, vdyn_ode_fn, positive_fn, symptom_fn, prob_s_ibar = 0.1, prob_fp=0.0, Epi_Model=od.SIR,\n",
    "                 duration= start_day0, Epi_cadence = 0.5, Vir_cadence = 0.0675, phi_s = 0.55, psi_s = 0.1)\n",
    "    ll,pp = loglike.__call__(test_data, epipar, vpar, pospar, sympar)\n",
    "    epi_state = [i,s,1.0-i-s]\n",
    "    ll = ll + joint_log_prior(R0, nu, epi_state).numpy()\n",
    "    return sum(ll)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial time\n",
      "tf.Tensor(-21.0, shape=(), dtype=float32)\n",
      "final time\n",
      "tf.Tensor(10.0, shape=(), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=-4256.0967>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joint_log_prob(test_data, R0 = 1.8, nu = 0.1, epi_state = [0.01,0.9, 0.09])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute log_lik \n",
    "# Impute things we don't want to sample, eg. observations\n",
    "\n",
    "unnormalized_posterior_log_prob = partial(joint_log_prob, test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.8, 0.1, [0.001, 0.99, 0.009000000000000008]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize parameters\n",
    "\n",
    "R0 = 1.8; nu0 = 0.1; i0 = 0.001; s0 = 0.99; r0 = 1.0 - i0 -s0;\n",
    "initial_state = [R0, nu0, [i0, s0, r0]]\n",
    "initial_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform all parameters so that parameter spaces are unconstrained\n",
    "# Every parameter needs a bijector, might be 'Identity'\n",
    "\n",
    "unconstraining_bijectors = [\n",
    "    tfb.Log(),\n",
    "    tfb.Invert(tfb.Sigmoid()),\n",
    "    tfb.Invert(tfb.IteratedSigmoidCentered())\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sample = 50\n",
    "n_burnin = 30\n",
    "n_adaptation = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@tf.function(autograph=False)\n",
    "def sample():\n",
    "    return tfp.mcmc.sample_chain(\n",
    "        num_results = n_sample,\n",
    "        num_burnin_steps = n_burnin,\n",
    "        current_state = initial_state,\n",
    "        kernel = tfp.mcmc.SimpleStepSizeAdaptation(\n",
    "            tfp.mcmc.TransformedTransitionKernel(\n",
    "                inner_kernel = tfp.mcmc.HamiltonianMonteCarlo(\n",
    "                    target_log_prob_fn = unnormalized_posterior_log_prob,\n",
    "                     step_size = 0.01,\n",
    "                     num_leapfrog_steps = 2),\n",
    "                bijector = unconstraining_bijectors),\n",
    "             num_adaptation_steps = n_adaptation),\n",
    "        trace_fn=lambda _, pkr: pkr.inner_results.inner_results.is_accepted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial time\n",
      "tf.Tensor(-21.0, shape=(), dtype=float32)\n",
      "final time\n",
      "tf.Tensor(10.0, shape=(), dtype=float32)\n",
      "initial time\n",
      "tf.Tensor(-21.0, shape=(), dtype=float32)\n",
      "final time\n",
      "tf.Tensor(10.0, shape=(), dtype=float32)\n",
      "initial time\n",
      "tf.Tensor(-21.0, shape=(), dtype=float32)\n",
      "final time\n",
      "tf.Tensor(10.0, shape=(), dtype=float32)\n",
      "initial time\n",
      "tf.Tensor(-21.0, shape=(), dtype=float32)\n",
      "final time\n",
      "tf.Tensor(10.0, shape=(), dtype=float32)\n",
      "initial time\n",
      "tf.Tensor(-21.0, shape=(), dtype=float32)\n",
      "final time\n",
      "tf.Tensor(10.0, shape=(), dtype=float32)\n",
      "initial time\n",
      "tf.Tensor(-21.0, shape=(), dtype=float32)\n",
      "final time\n",
      "tf.Tensor(10.0, shape=(), dtype=float32)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The two structures don't have the same nested structure.\n\nFirst structure: type=list str=[TensorSpec(shape=(), dtype=tf.int32, name=None), TensorSpec(shape=(2,), dtype=tf.int32, name=None), [TensorSpec(shape=(), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.float32, name=None), [TensorSpec(shape=(), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.float32, name=None)]], SimpleStepSizeAdaptationResults(\n  inner_results=TransformedTransitionKernelResults(\n      transformed_state=[TensorSpec(shape=(), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.float32, name=None), TensorSpec(shape=(4,), dtype=tf.float32, name=None)],\n      inner_results=MetropolisHastingsKernelResults(\n          accepted_results=UncalibratedHamiltonianMonteCarloKernelResults(\n              log_acceptance_correction=TensorSpec(shape=(), dtype=tf.float32, name=None),\n              target_log_prob=TensorSpec(shape=(), dtype=tf.float32, name=None),\n              grads_target_log_prob=[TensorSpec(shape=(), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.float32, name=None), TensorSpec(shape=(4,), dtype=tf.float32, name=None)],\n              initial_momentum=[TensorSpec(shape=(), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.float32, name=None), TensorSpec(shape=(4,), dtype=tf.float32, name=None)],\n              final_momentum=[TensorSpec(shape=(), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.float32, name=None), TensorSpec(shape=(4,), dtype=tf.float32, name=None)],\n              step_size=TensorSpec(shape=(), dtype=tf.float32, name=None),\n              num_leapfrog_steps=TensorSpec(shape=(), dtype=tf.int32, name=None),\n              seed=[]\n            ),\n          is_accepted=TensorSpec(shape=(), dtype=tf.bool, name=None),\n          log_accept_ratio=TensorSpec(shape=(), dtype=tf.float32, name=None),\n          proposed_state=[TensorSpec(shape=(), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.float32, name=None), TensorSpec(shape=(4,), dtype=tf.float32, name=None)],\n          proposed_results=UncalibratedHamiltonianMonteCarloKernelResults(\n              log_acceptance_correction=TensorSpec(shape=(), dtype=tf.float32, name=None),\n              target_log_prob=TensorSpec(shape=(), dtype=tf.float32, name=None),\n              grads_target_log_prob=[TensorSpec(shape=(), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.float32, name=None), TensorSpec(shape=(4,), dtype=tf.float32, name=None)],\n              initial_momentum=[TensorSpec(shape=(), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.float32, name=None), TensorSpec(shape=(4,), dtype=tf.float32, name=None)],\n              final_momentum=[TensorSpec(shape=(), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.float32, name=None), TensorSpec(shape=(4,), dtype=tf.float32, name=None)],\n              step_size=TensorSpec(shape=(), dtype=tf.float32, name=None),\n              num_leapfrog_steps=TensorSpec(shape=(), dtype=tf.int32, name=None),\n              seed=TensorSpec(shape=(2,), dtype=tf.int32, name=None)\n            ),\n          extra=[],\n          seed=TensorSpec(shape=(2,), dtype=tf.int32, name=None)\n        )\n    ),\n  target_accept_prob=TensorSpec(shape=(), dtype=tf.float32, name=None),\n  adaptation_rate=TensorSpec(shape=(), dtype=tf.float32, name=None),\n  step=TensorSpec(shape=(), dtype=tf.int32, name=None),\n  new_step_size=TensorSpec(shape=(), dtype=tf.float32, name=None)\n)]\n\nSecond structure: type=list str=[1, <tf.Tensor: shape=(2,), dtype=int32, numpy=array([ 169751232, 1748927931], dtype=int32)>, [<tf.Tensor: shape=(), dtype=float32, numpy=1.8>, <tf.Tensor: shape=(), dtype=float32, numpy=0.099999964>, <tf.Tensor: shape=(3,), dtype=float32, numpy=array([0.00100017, 0.98999983, 0.00899988], dtype=float32)>], SimpleStepSizeAdaptationResults(\n  inner_results=TransformedTransitionKernelResults(\n      transformed_state=[<tf.Tensor: shape=(), dtype=float32, numpy=6.0496473>, <tf.Tensor: shape=(), dtype=float32, numpy=0.5249792>, <tf.Tensor: shape=(4,), dtype=float32, numpy=array([0.25018758, 0.4301471 , 0.16055189, 0.1591134 ], dtype=float32)>],\n      inner_results=MetropolisHastingsKernelResults(\n          accepted_results=UncalibratedHamiltonianMonteCarloKernelResults(\n              log_acceptance_correction=<tf.Tensor: shape=(), dtype=float32, numpy=0.0>,\n              target_log_prob=<tf.Tensor: shape=(), dtype=float32, numpy=-2334.941>,\n              grads_target_log_prob=[<tf.Tensor: shape=(), dtype=float32, numpy=-0.1652989>, <tf.Tensor: shape=(), dtype=float32, numpy=0.20033339>, <tf.Tensor: shape=(4,), dtype=float32, numpy=array([2.2878242 , 3.960039  , 0.05630922, 0.        ], dtype=float32)>],\n              initial_momentum=[<tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(4,), dtype=float32, numpy=array([0., 0., 0., 0.], dtype=float32)>],\n              final_momentum=[<tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(4,), dtype=float32, numpy=array([0., 0., 0., 0.], dtype=float32)>],\n              step_size=<tf.Tensor: shape=(), dtype=float32, numpy=0.01>,\n              num_leapfrog_steps=<tf.Tensor: shape=(), dtype=int32, numpy=2>,\n              seed=[]\n            ),\n          is_accepted=<tf.Tensor: shape=(), dtype=bool, numpy=False>,\n          log_accept_ratio=<tf.Tensor: shape=(), dtype=float32, numpy=-inf>,\n          proposed_state=[<tf.Tensor: shape=(), dtype=float32, numpy=6.029957>, <tf.Tensor: shape=(), dtype=float32, numpy=0.5033211>, <tf.Tensor: shape=(4,), dtype=float32, numpy=array([0.26968965, 0.43749148, 0.18217799, 0.15569884], dtype=float32)>],\n          proposed_results=UncalibratedHamiltonianMonteCarloKernelResults(\n              log_acceptance_correction=<tf.Tensor: shape=(), dtype=float32, numpy=-0.14856863>,\n              target_log_prob=<tf.Tensor: shape=(), dtype=float32, numpy=nan>,\n              grads_target_log_prob=[<tf.Tensor: shape=(), dtype=float32, numpy=-0.16583867>, <tf.Tensor: shape=(), dtype=float32, numpy=0.026570063>, <tf.Tensor: shape=(4,), dtype=float32, numpy=array([5.3302827, 6.75249  , 3.549111 , 0.       ], dtype=float32)>],\n              initial_momentum=[<tf.Tensor: shape=(), dtype=float32, numpy=-0.98287237>, <tf.Tensor: shape=(), dtype=float32, numpy=-1.0844703>, <tf.Tensor: shape=(4,), dtype=float32, numpy=array([ 0.9459811 ,  0.32201868,  1.0732824 , -0.17072785], dtype=float32)>],\n              final_momentum=[<tf.Tensor: shape=(), dtype=float32, numpy=-0.9861837>, <tf.Tensor: shape=(), dtype=float32, numpy=-1.0822031>, <tf.Tensor: shape=(4,), dtype=float32, numpy=array([ 1.019438  ,  0.42637998,  1.1067913 , -0.17072785], dtype=float32)>],\n              step_size=<tf.Tensor: shape=(), dtype=float32, numpy=0.01>,\n              num_leapfrog_steps=<tf.Tensor: shape=(), dtype=int32, numpy=2>,\n              seed=<tf.Tensor: shape=(2,), dtype=int32, numpy=array([-1792482709, -2029539736], dtype=int32)>\n            ),\n          extra=[],\n          seed=<tf.Tensor: shape=(2,), dtype=int32, numpy=array([0, 0], dtype=int32)>\n        )\n    ),\n  target_accept_prob=<tf.Tensor: shape=(), dtype=float32, numpy=0.75>,\n  adaptation_rate=<tf.Tensor: shape=(), dtype=float32, numpy=0.01>,\n  step=<tf.Tensor: shape=(), dtype=int32, numpy=1>,\n  new_step_size=<tf.Tensor: shape=(), dtype=float32, numpy=0.00990099>\n)]\n\nMore specifically: Substructure \"type=list str=[TensorSpec(shape=(), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.float32, name=None)]\" is a sequence, while substructure \"type=EagerTensor str=tf.Tensor([0.00100017 0.98999983 0.00899988], shape=(3,), dtype=float32)\" is not\nEntire first structure:\n[., ., [., ., [., ., .]], SimpleStepSizeAdaptationResults(\n  inner_results=TransformedTransitionKernelResults(\n      transformed_state=[., ., .],\n      inner_results=MetropolisHastingsKernelResults(\n          accepted_results=UncalibratedHamiltonianMonteCarloKernelResults(\n              log_acceptance_correction=.,\n              target_log_prob=.,\n              grads_target_log_prob=[., ., .],\n              initial_momentum=[., ., .],\n              final_momentum=[., ., .],\n              step_size=.,\n              num_leapfrog_steps=.,\n              seed=[]\n            ),\n          is_accepted=.,\n          log_accept_ratio=.,\n          proposed_state=[., ., .],\n          proposed_results=UncalibratedHamiltonianMonteCarloKernelResults(\n              log_acceptance_correction=.,\n              target_log_prob=.,\n              grads_target_log_prob=[., ., .],\n              initial_momentum=[., ., .],\n              final_momentum=[., ., .],\n              step_size=.,\n              num_leapfrog_steps=.,\n              seed=.\n            ),\n          extra=[],\n          seed=.\n        )\n    ),\n  target_accept_prob=.,\n  adaptation_rate=.,\n  step=.,\n  new_step_size=.\n)]\nEntire second structure:\n[., ., [., ., .], SimpleStepSizeAdaptationResults(\n  inner_results=TransformedTransitionKernelResults(\n      transformed_state=[., ., .],\n      inner_results=MetropolisHastingsKernelResults(\n          accepted_results=UncalibratedHamiltonianMonteCarloKernelResults(\n              log_acceptance_correction=.,\n              target_log_prob=.,\n              grads_target_log_prob=[., ., .],\n              initial_momentum=[., ., .],\n              final_momentum=[., ., .],\n              step_size=.,\n              num_leapfrog_steps=.,\n              seed=[]\n            ),\n          is_accepted=.,\n          log_accept_ratio=.,\n          proposed_state=[., ., .],\n          proposed_results=UncalibratedHamiltonianMonteCarloKernelResults(\n              log_acceptance_correction=.,\n              target_log_prob=.,\n              grads_target_log_prob=[., ., .],\n              initial_momentum=[., ., .],\n              final_momentum=[., ., .],\n              step_size=.,\n              num_leapfrog_steps=.,\n              seed=.\n            ),\n          extra=[],\n          seed=.\n        )\n    ),\n  target_accept_prob=.,\n  adaptation_rate=.,\n  step=.,\n  new_step_size=.\n)]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36massert_same_structure\u001b[0;34m(nest1, nest2, check_types, expand_composites)\u001b[0m\n\u001b[1;32m    394\u001b[0m     _pywrap_utils.AssertSameStructure(nest1, nest2, check_types,\n\u001b[0;32m--> 395\u001b[0;31m                                       expand_composites)\n\u001b[0m\u001b[1;32m    396\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The two structures don't have the same nested structure.\n\nFirst structure: type=list str=[TensorSpec(shape=(), dtype=tf.int32, name=None), TensorSpec(shape=(2,), dtype=tf.int32, name=None), [TensorSpec(shape=(), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.float32, name=None), [TensorSpec(shape=(), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.float32, name=None)]], SimpleStepSizeAdaptationResults(\n  inner_results=TransformedTransitionKernelResults(\n      transformed_state=[TensorSpec(shape=(), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.float32, name=None), TensorSpec(shape=(4,), dtype=tf.float32, name=None)],\n      inner_results=MetropolisHastingsKernelResults(\n          accepted_results=UncalibratedHamiltonianMonteCarloKernelResults(\n              log_acceptance_correction=TensorSpec(shape=(), dtype=tf.float32, name=None),\n              target_log_prob=TensorSpec(shape=(), dtype=tf.float32, name=None),\n              grads_target_log_prob=[TensorSpec(shape=(), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.float32, name=None), TensorSpec(shape=(4,), dtype=tf.float32, name=None)],\n              initial_momentum=[TensorSpec(shape=(), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.float32, name=None), TensorSpec(shape=(4,), dtype=tf.float32, name=None)],\n              final_momentum=[TensorSpec(shape=(), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.float32, name=None), TensorSpec(shape=(4,), dtype=tf.float32, name=None)],\n              step_size=TensorSpec(shape=(), dtype=tf.float32, name=None),\n              num_leapfrog_steps=TensorSpec(shape=(), dtype=tf.int32, name=None),\n              seed=[]\n            ),\n          is_accepted=TensorSpec(shape=(), dtype=tf.bool, name=None),\n          log_accept_ratio=TensorSpec(shape=(), dtype=tf.float32, name=None),\n          proposed_state=[TensorSpec(shape=(), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.float32, name=None), TensorSpec(shape=(4,), dtype=tf.float32, name=None)],\n          proposed_results=UncalibratedHamiltonianMonteCarloKernelResults(\n              log_acceptance_correction=TensorSpec(shape=(), dtype=tf.float32, name=None),\n              target_log_prob=TensorSpec(shape=(), dtype=tf.float32, name=None),\n              grads_target_log_prob=[TensorSpec(shape=(), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.float32, name=None), TensorSpec(shape=(4,), dtype=tf.float32, name=None)],\n              initial_momentum=[TensorSpec(shape=(), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.float32, name=None), TensorSpec(shape=(4,), dtype=tf.float32, name=None)],\n              final_momentum=[TensorSpec(shape=(), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.float32, name=None), TensorSpec(shape=(4,), dtype=tf.float32, name=None)],\n              step_size=TensorSpec(shape=(), dtype=tf.float32, name=None),\n              num_leapfrog_steps=TensorSpec(shape=(), dtype=tf.int32, name=None),\n              seed=TensorSpec(shape=(2,), dtype=tf.int32, name=None)\n            ),\n          extra=[],\n          seed=TensorSpec(shape=(2,), dtype=tf.int32, name=None)\n        )\n    ),\n  target_accept_prob=TensorSpec(shape=(), dtype=tf.float32, name=None),\n  adaptation_rate=TensorSpec(shape=(), dtype=tf.float32, name=None),\n  step=TensorSpec(shape=(), dtype=tf.int32, name=None),\n  new_step_size=TensorSpec(shape=(), dtype=tf.float32, name=None)\n)]\n\nSecond structure: type=list str=[1, <tf.Tensor: shape=(2,), dtype=int32, numpy=array([ 169751232, 1748927931], dtype=int32)>, [<tf.Tensor: shape=(), dtype=float32, numpy=1.8>, <tf.Tensor: shape=(), dtype=float32, numpy=0.099999964>, <tf.Tensor: shape=(3,), dtype=float32, numpy=array([0.00100017, 0.98999983, 0.00899988], dtype=float32)>], SimpleStepSizeAdaptationResults(\n  inner_results=TransformedTransitionKernelResults(\n      transformed_state=[<tf.Tensor: shape=(), dtype=float32, numpy=6.0496473>, <tf.Tensor: shape=(), dtype=float32, numpy=0.5249792>, <tf.Tensor: shape=(4,), dtype=float32, numpy=array([0.25018758, 0.4301471 , 0.16055189, 0.1591134 ], dtype=float32)>],\n      inner_results=MetropolisHastingsKernelResults(\n          accepted_results=UncalibratedHamiltonianMonteCarloKernelResults(\n              log_acceptance_correction=<tf.Tensor: shape=(), dtype=float32, numpy=0.0>,\n              target_log_prob=<tf.Tensor: shape=(), dtype=float32, numpy=-2334.941>,\n              grads_target_log_prob=[<tf.Tensor: shape=(), dtype=float32, numpy=-0.1652989>, <tf.Tensor: shape=(), dtype=float32, numpy=0.20033339>, <tf.Tensor: shape=(4,), dtype=float32, numpy=array([2.2878242 , 3.960039  , 0.05630922, 0.        ], dtype=float32)>],\n              initial_momentum=[<tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(4,), dtype=float32, numpy=array([0., 0., 0., 0.], dtype=float32)>],\n              final_momentum=[<tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(4,), dtype=float32, numpy=array([0., 0., 0., 0.], dtype=float32)>],\n              step_size=<tf.Tensor: shape=(), dtype=float32, numpy=0.01>,\n              num_leapfrog_steps=<tf.Tensor: shape=(), dtype=int32, numpy=2>,\n              seed=[]\n            ),\n          is_accepted=<tf.Tensor: shape=(), dtype=bool, numpy=False>,\n          log_accept_ratio=<tf.Tensor: shape=(), dtype=float32, numpy=-inf>,\n          proposed_state=[<tf.Tensor: shape=(), dtype=float32, numpy=6.029957>, <tf.Tensor: shape=(), dtype=float32, numpy=0.5033211>, <tf.Tensor: shape=(4,), dtype=float32, numpy=array([0.26968965, 0.43749148, 0.18217799, 0.15569884], dtype=float32)>],\n          proposed_results=UncalibratedHamiltonianMonteCarloKernelResults(\n              log_acceptance_correction=<tf.Tensor: shape=(), dtype=float32, numpy=-0.14856863>,\n              target_log_prob=<tf.Tensor: shape=(), dtype=float32, numpy=nan>,\n              grads_target_log_prob=[<tf.Tensor: shape=(), dtype=float32, numpy=-0.16583867>, <tf.Tensor: shape=(), dtype=float32, numpy=0.026570063>, <tf.Tensor: shape=(4,), dtype=float32, numpy=array([5.3302827, 6.75249  , 3.549111 , 0.       ], dtype=float32)>],\n              initial_momentum=[<tf.Tensor: shape=(), dtype=float32, numpy=-0.98287237>, <tf.Tensor: shape=(), dtype=float32, numpy=-1.0844703>, <tf.Tensor: shape=(4,), dtype=float32, numpy=array([ 0.9459811 ,  0.32201868,  1.0732824 , -0.17072785], dtype=float32)>],\n              final_momentum=[<tf.Tensor: shape=(), dtype=float32, numpy=-0.9861837>, <tf.Tensor: shape=(), dtype=float32, numpy=-1.0822031>, <tf.Tensor: shape=(4,), dtype=float32, numpy=array([ 1.019438  ,  0.42637998,  1.1067913 , -0.17072785], dtype=float32)>],\n              step_size=<tf.Tensor: shape=(), dtype=float32, numpy=0.01>,\n              num_leapfrog_steps=<tf.Tensor: shape=(), dtype=int32, numpy=2>,\n              seed=<tf.Tensor: shape=(2,), dtype=int32, numpy=array([-1792482709, -2029539736], dtype=int32)>\n            ),\n          extra=[],\n          seed=<tf.Tensor: shape=(2,), dtype=int32, numpy=array([0, 0], dtype=int32)>\n        )\n    ),\n  target_accept_prob=<tf.Tensor: shape=(), dtype=float32, numpy=0.75>,\n  adaptation_rate=<tf.Tensor: shape=(), dtype=float32, numpy=0.01>,\n  step=<tf.Tensor: shape=(), dtype=int32, numpy=1>,\n  new_step_size=<tf.Tensor: shape=(), dtype=float32, numpy=0.00990099>\n)]\n\nMore specifically: Substructure \"type=list str=[TensorSpec(shape=(), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.float32, name=None)]\" is a sequence, while substructure \"type=EagerTensor str=tf.Tensor([0.00100017 0.98999983 0.00899988], shape=(3,), dtype=float32)\" is not",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-35dbef5555f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mR0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepi_state\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_accepted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-282be1355eb9>\u001b[0m in \u001b[0;36msample\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m                 bijector = unconstraining_bijectors),\n\u001b[1;32m     14\u001b[0m              num_adaptation_steps = n_adaptation),\n\u001b[0;32m---> 15\u001b[0;31m         trace_fn=lambda _, pkr: pkr.inner_results.inner_results.is_accepted)\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_probability/python/mcmc/sample.py\u001b[0m in \u001b[0;36msample_chain\u001b[0;34m(num_results, current_state, previous_kernel_results, kernel, num_burnin_steps, num_steps_between_results, trace_fn, return_final_kernel_results, parallel_iterations, seed, name)\u001b[0m\n\u001b[1;32m    369\u001b[0m             seed_state_and_results[1], trace_fn(*seed_state_and_results[1:])),\n\u001b[1;32m    370\u001b[0m         \u001b[0;31m# pylint: enable=g-long-lambda\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m         parallel_iterations=parallel_iterations)\n\u001b[0m\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_final_kernel_results\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_probability/python/mcmc/internal/util.py\u001b[0m in \u001b[0;36mtrace_scan\u001b[0;34m(loop_fn, initial_state, elems, trace_fn, trace_criterion_fn, static_trace_allocation_size, parallel_iterations, name)\u001b[0m\n\u001b[1;32m    454\u001b[0m         \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_body\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m         \u001b[0mloop_vars\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace_arrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m         parallel_iterations=parallel_iterations)\n\u001b[0m\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m     \u001b[0mstacked_trace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace_arrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    572\u001b[0m                   \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'in a future version'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m                   if date is None else ('after %s' % date), instructions)\n\u001b[0;32m--> 574\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     doc = _add_deprecated_arg_value_notice_to_docstring(\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop_v2\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, maximum_iterations, name)\u001b[0m\n\u001b[1;32m   2497\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2498\u001b[0m       \u001b[0mmaximum_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaximum_iterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2499\u001b[0;31m       return_same_structure=True)\n\u001b[0m\u001b[1;32m   2500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[1;32m   2733\u001b[0m                                               list(loop_vars))\n\u001b[1;32m   2734\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0mcond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2735\u001b[0;31m         \u001b[0mloop_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2736\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtry_to_pack\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_basetuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2737\u001b[0m           \u001b[0mpacked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_probability/python/mcmc/internal/util.py\u001b[0m in \u001b[0;36m_body\u001b[0;34m(i, state, num_steps_traced, trace_arrays)\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_steps_traced\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace_arrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m       \u001b[0melem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melems_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m       \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloop_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m       trace_arrays, num_steps_traced = prefer_static.cond(\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_probability/python/mcmc/sample.py\u001b[0m in \u001b[0;36m_trace_scan_fn\u001b[0;34m(seed_state_and_results, num_steps)\u001b[0m\n\u001b[1;32m    353\u001b[0m           \u001b[0mbody_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_seeded_one_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m           \u001b[0minitial_loop_vars\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed_state_and_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m           parallel_iterations=parallel_iterations)\n\u001b[0m\u001b[1;32m    356\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_kernel_results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_probability/python/mcmc/internal/util.py\u001b[0m in \u001b[0;36msmart_for_loop\u001b[0;34m(loop_num_iter, body_fn, initial_loop_vars, parallel_iterations, name)\u001b[0m\n\u001b[1;32m    343\u001b[0m           \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m           \u001b[0mloop_vars\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minitial_loop_vars\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m           \u001b[0mparallel_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparallel_iterations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m       )[1:]\n\u001b[1;32m    347\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitial_loop_vars\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    572\u001b[0m                   \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'in a future version'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m                   if date is None else ('after %s' % date), instructions)\n\u001b[0;32m--> 574\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     doc = _add_deprecated_arg_value_notice_to_docstring(\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop_v2\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, maximum_iterations, name)\u001b[0m\n\u001b[1;32m   2497\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2498\u001b[0m       \u001b[0mmaximum_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaximum_iterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2499\u001b[0;31m       return_same_structure=True)\n\u001b[0m\u001b[1;32m   2500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[1;32m   2737\u001b[0m           \u001b[0mpacked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2738\u001b[0m           \u001b[0mloop_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2739\u001b[0;31m         \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_same_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloop_var_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2741\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36massert_same_structure\u001b[0;34m(nest1, nest2, check_types, expand_composites)\u001b[0m\n\u001b[1;32m    400\u001b[0m                   \u001b[0;34m\"Entire first structure:\\n%s\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m                   \u001b[0;34m\"Entire second structure:\\n%s\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m                   % (str(e), str1, str2))\n\u001b[0m\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The two structures don't have the same nested structure.\n\nFirst structure: type=list str=[TensorSpec(shape=(), dtype=tf.int32, name=None), TensorSpec(shape=(2,), dtype=tf.int32, name=None), [TensorSpec(shape=(), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.float32, name=None), [TensorSpec(shape=(), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.float32, name=None)]], SimpleStepSizeAdaptationResults(\n  inner_results=TransformedTransitionKernelResults(\n      transformed_state=[TensorSpec(shape=(), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.float32, name=None), TensorSpec(shape=(4,), dtype=tf.float32, name=None)],\n      inner_results=MetropolisHastingsKernelResults(\n          accepted_results=UncalibratedHamiltonianMonteCarloKernelResults(\n              log_acceptance_correction=TensorSpec(shape=(), dtype=tf.float32, name=None),\n              target_log_prob=TensorSpec(shape=(), dtype=tf.float32, name=None),\n              grads_target_log_prob=[TensorSpec(shape=(), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.float32, name=None), TensorSpec(shape=(4,), dtype=tf.float32, name=None)],\n              initial_momentum=[TensorSpec(shape=(), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.float32, name=None), TensorSpec(shape=(4,), dtype=tf.float32, name=None)],\n              final_momentum=[TensorSpec(shape=(), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.float32, name=None), TensorSpec(shape=(4,), dtype=tf.float32, name=None)],\n              step_size=TensorSpec(shape=(), dtype=tf.float32, name=None),\n              num_leapfrog_steps=TensorSpec(shape=(), dtype=tf.int32, name=None),\n              seed=[]\n            ),\n          is_accepted=TensorSpec(shape=(), dtype=tf.bool, name=None),\n          log_accept_ratio=TensorSpec(shape=(), dtype=tf.float32, name=None),\n          proposed_state=[TensorSpec(shape=(), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.float32, name=None), TensorSpec(shape=(4,), dtype=tf.float32, name=None)],\n          proposed_results=UncalibratedHamiltonianMonteCarloKernelResults(\n              log_acceptance_correction=TensorSpec(shape=(), dtype=tf.float32, name=None),\n              target_log_prob=TensorSpec(shape=(), dtype=tf.float32, name=None),\n              grads_target_log_prob=[TensorSpec(shape=(), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.float32, name=None), TensorSpec(shape=(4,), dtype=tf.float32, name=None)],\n              initial_momentum=[TensorSpec(shape=(), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.float32, name=None), TensorSpec(shape=(4,), dtype=tf.float32, name=None)],\n              final_momentum=[TensorSpec(shape=(), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.float32, name=None), TensorSpec(shape=(4,), dtype=tf.float32, name=None)],\n              step_size=TensorSpec(shape=(), dtype=tf.float32, name=None),\n              num_leapfrog_steps=TensorSpec(shape=(), dtype=tf.int32, name=None),\n              seed=TensorSpec(shape=(2,), dtype=tf.int32, name=None)\n            ),\n          extra=[],\n          seed=TensorSpec(shape=(2,), dtype=tf.int32, name=None)\n        )\n    ),\n  target_accept_prob=TensorSpec(shape=(), dtype=tf.float32, name=None),\n  adaptation_rate=TensorSpec(shape=(), dtype=tf.float32, name=None),\n  step=TensorSpec(shape=(), dtype=tf.int32, name=None),\n  new_step_size=TensorSpec(shape=(), dtype=tf.float32, name=None)\n)]\n\nSecond structure: type=list str=[1, <tf.Tensor: shape=(2,), dtype=int32, numpy=array([ 169751232, 1748927931], dtype=int32)>, [<tf.Tensor: shape=(), dtype=float32, numpy=1.8>, <tf.Tensor: shape=(), dtype=float32, numpy=0.099999964>, <tf.Tensor: shape=(3,), dtype=float32, numpy=array([0.00100017, 0.98999983, 0.00899988], dtype=float32)>], SimpleStepSizeAdaptationResults(\n  inner_results=TransformedTransitionKernelResults(\n      transformed_state=[<tf.Tensor: shape=(), dtype=float32, numpy=6.0496473>, <tf.Tensor: shape=(), dtype=float32, numpy=0.5249792>, <tf.Tensor: shape=(4,), dtype=float32, numpy=array([0.25018758, 0.4301471 , 0.16055189, 0.1591134 ], dtype=float32)>],\n      inner_results=MetropolisHastingsKernelResults(\n          accepted_results=UncalibratedHamiltonianMonteCarloKernelResults(\n              log_acceptance_correction=<tf.Tensor: shape=(), dtype=float32, numpy=0.0>,\n              target_log_prob=<tf.Tensor: shape=(), dtype=float32, numpy=-2334.941>,\n              grads_target_log_prob=[<tf.Tensor: shape=(), dtype=float32, numpy=-0.1652989>, <tf.Tensor: shape=(), dtype=float32, numpy=0.20033339>, <tf.Tensor: shape=(4,), dtype=float32, numpy=array([2.2878242 , 3.960039  , 0.05630922, 0.        ], dtype=float32)>],\n              initial_momentum=[<tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(4,), dtype=float32, numpy=array([0., 0., 0., 0.], dtype=float32)>],\n              final_momentum=[<tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(4,), dtype=float32, numpy=array([0., 0., 0., 0.], dtype=float32)>],\n              step_size=<tf.Tensor: shape=(), dtype=float32, numpy=0.01>,\n              num_leapfrog_steps=<tf.Tensor: shape=(), dtype=int32, numpy=2>,\n              seed=[]\n            ),\n          is_accepted=<tf.Tensor: shape=(), dtype=bool, numpy=False>,\n          log_accept_ratio=<tf.Tensor: shape=(), dtype=float32, numpy=-inf>,\n          proposed_state=[<tf.Tensor: shape=(), dtype=float32, numpy=6.029957>, <tf.Tensor: shape=(), dtype=float32, numpy=0.5033211>, <tf.Tensor: shape=(4,), dtype=float32, numpy=array([0.26968965, 0.43749148, 0.18217799, 0.15569884], dtype=float32)>],\n          proposed_results=UncalibratedHamiltonianMonteCarloKernelResults(\n              log_acceptance_correction=<tf.Tensor: shape=(), dtype=float32, numpy=-0.14856863>,\n              target_log_prob=<tf.Tensor: shape=(), dtype=float32, numpy=nan>,\n              grads_target_log_prob=[<tf.Tensor: shape=(), dtype=float32, numpy=-0.16583867>, <tf.Tensor: shape=(), dtype=float32, numpy=0.026570063>, <tf.Tensor: shape=(4,), dtype=float32, numpy=array([5.3302827, 6.75249  , 3.549111 , 0.       ], dtype=float32)>],\n              initial_momentum=[<tf.Tensor: shape=(), dtype=float32, numpy=-0.98287237>, <tf.Tensor: shape=(), dtype=float32, numpy=-1.0844703>, <tf.Tensor: shape=(4,), dtype=float32, numpy=array([ 0.9459811 ,  0.32201868,  1.0732824 , -0.17072785], dtype=float32)>],\n              final_momentum=[<tf.Tensor: shape=(), dtype=float32, numpy=-0.9861837>, <tf.Tensor: shape=(), dtype=float32, numpy=-1.0822031>, <tf.Tensor: shape=(4,), dtype=float32, numpy=array([ 1.019438  ,  0.42637998,  1.1067913 , -0.17072785], dtype=float32)>],\n              step_size=<tf.Tensor: shape=(), dtype=float32, numpy=0.01>,\n              num_leapfrog_steps=<tf.Tensor: shape=(), dtype=int32, numpy=2>,\n              seed=<tf.Tensor: shape=(2,), dtype=int32, numpy=array([-1792482709, -2029539736], dtype=int32)>\n            ),\n          extra=[],\n          seed=<tf.Tensor: shape=(2,), dtype=int32, numpy=array([0, 0], dtype=int32)>\n        )\n    ),\n  target_accept_prob=<tf.Tensor: shape=(), dtype=float32, numpy=0.75>,\n  adaptation_rate=<tf.Tensor: shape=(), dtype=float32, numpy=0.01>,\n  step=<tf.Tensor: shape=(), dtype=int32, numpy=1>,\n  new_step_size=<tf.Tensor: shape=(), dtype=float32, numpy=0.00990099>\n)]\n\nMore specifically: Substructure \"type=list str=[TensorSpec(shape=(), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.float32, name=None)]\" is a sequence, while substructure \"type=EagerTensor str=tf.Tensor([0.00100017 0.98999983 0.00899988], shape=(3,), dtype=float32)\" is not\nEntire first structure:\n[., ., [., ., [., ., .]], SimpleStepSizeAdaptationResults(\n  inner_results=TransformedTransitionKernelResults(\n      transformed_state=[., ., .],\n      inner_results=MetropolisHastingsKernelResults(\n          accepted_results=UncalibratedHamiltonianMonteCarloKernelResults(\n              log_acceptance_correction=.,\n              target_log_prob=.,\n              grads_target_log_prob=[., ., .],\n              initial_momentum=[., ., .],\n              final_momentum=[., ., .],\n              step_size=.,\n              num_leapfrog_steps=.,\n              seed=[]\n            ),\n          is_accepted=.,\n          log_accept_ratio=.,\n          proposed_state=[., ., .],\n          proposed_results=UncalibratedHamiltonianMonteCarloKernelResults(\n              log_acceptance_correction=.,\n              target_log_prob=.,\n              grads_target_log_prob=[., ., .],\n              initial_momentum=[., ., .],\n              final_momentum=[., ., .],\n              step_size=.,\n              num_leapfrog_steps=.,\n              seed=.\n            ),\n          extra=[],\n          seed=.\n        )\n    ),\n  target_accept_prob=.,\n  adaptation_rate=.,\n  step=.,\n  new_step_size=.\n)]\nEntire second structure:\n[., ., [., ., .], SimpleStepSizeAdaptationResults(\n  inner_results=TransformedTransitionKernelResults(\n      transformed_state=[., ., .],\n      inner_results=MetropolisHastingsKernelResults(\n          accepted_results=UncalibratedHamiltonianMonteCarloKernelResults(\n              log_acceptance_correction=.,\n              target_log_prob=.,\n              grads_target_log_prob=[., ., .],\n              initial_momentum=[., ., .],\n              final_momentum=[., ., .],\n              step_size=.,\n              num_leapfrog_steps=.,\n              seed=[]\n            ),\n          is_accepted=.,\n          log_accept_ratio=.,\n          proposed_state=[., ., .],\n          proposed_results=UncalibratedHamiltonianMonteCarloKernelResults(\n              log_acceptance_correction=.,\n              target_log_prob=.,\n              grads_target_log_prob=[., ., .],\n              initial_momentum=[., ., .],\n              final_momentum=[., ., .],\n              step_size=.,\n              num_leapfrog_steps=.,\n              seed=.\n            ),\n          extra=[],\n          seed=.\n        )\n    ),\n  target_accept_prob=.,\n  adaptation_rate=.,\n  step=.,\n  new_step_size=.\n)]"
     ]
    }
   ],
   "source": [
    "[R0, nu, epi_state], is_accepted = sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute posterior means of Epidemic parameters\n",
    "\n",
    "acceptance_rate = tf.reduce_mean(tf.cast(is_accepted, dtype=tf.float32)).numpy()\n",
    "mean_R0 = tf.reduce_mean(R0, axis=0).numpy()\n",
    "mean_nu = tf.reduce_mean(nu, axis=0).numpy()\n",
    "i_s = np.array(i_s)\n",
    "i = i_s[...,0]\n",
    "s = i_s[...,0]\n",
    "mean_i = tf.reduce_mean(i, axis=0).numpy()\n",
    "mean_s = tf.reduce_mean(s, axis=0).numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('acceptance_rate:', acceptance_rate)\n",
    "print('avg basic reproduction number:', mean_R0)\n",
    "print('avg recovery rate:', mean_nu)\n",
    "print('avg infected', mean_i)\n",
    "print('avg susceptible', mean_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecast Infection Rate, 7 Days into Future\n",
    "forecast_window = 7\n",
    "R0_sample = R0[n_burnin:n_sample]\n",
    "nu_sample = nu[n_burnin:n_sample]\n",
    "i_sample = i[n_burnin:n_sample]\n",
    "s_sample = s[n_burnin:n_sample]\n",
    "\n",
    "mod = od.SIR(par)\n",
    "\n",
    "par=tf.constant(np.array([[R0_sample[1].numpy(), 5.0E-08, nu_sample[1].numpy()]], dtype=np.float32))\n",
    "init_state=tf.constant(np.array([[i_sample[1].numpy(),s_sample[1].numpy()]], dtype=np.float32))\n",
    "init_time=tf.constant(0.0)\n",
    "int_duration = end_day - start_day + forecast_window\n",
    "soln_times=tf.constant(np.linspace(0.0,int_duration,num=int_duration,dtype=np.float32))\n",
    "dp = tfp.math.ode.DormandPrince()\n",
    "results = dp.solve(mod.RHS, init_time, init_state, solution_times=soln_times)\n",
    "i_forecast = results.states[:,0,0].numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = 1\n",
    "while id < len(R0_sample):\n",
    "    par=tf.constant(np.array([[R0_sample[id].numpy(), 5.0E-08, nu_sample[id].numpy()]], dtype=np.float32))\n",
    "    init_state=tf.constant(np.array([[i_sample[id].numpy(),s_sample[id].numpy()]], dtype=np.float32))\n",
    "    init_time=tf.constant(0.0)\n",
    "    soln_times=tf.constant(np.linspace(0.0,int_duration,num=int_duration,dtype=np.float32))\n",
    "    dp = tfp.math.ode.DormandPrince()\n",
    "    results = dp.solve(mod.RHS, init_time, init_state, solution_times=soln_times)\n",
    "    i_forecast = np.column_stack((i_forecast, results.states[:,0,0].numpy()))\n",
    "    id += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_forecast_lower = []\n",
    "i_forecast_upper = []\n",
    "i_forecast_median = []\n",
    "\n",
    "for j in range(forecast_window):\n",
    "    id = end_day - start_day + j\n",
    "    i_forecast_lower.append(np.percentile(i_forecast[id], 5))\n",
    "    i_forecast_upper.append(np.percentile(i_forecast[id], 95))\n",
    "    i_forecast_median.append(np.percentile(i_forecast[id], 50))\n",
    "    \n",
    "print(i_forecast_lower)\n",
    "print(i_forecast_upper)\n",
    "print(i_forecast_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par=tf.constant(np.array([[1.8, 5.0E-08,0.1]], dtype=np.float32))\n",
    "mod = od.SIR(par)\n",
    "init_state=tf.constant(np.array([[0.001,0.999]], dtype=np.float32))\n",
    "init_time=tf.constant(0.0)\n",
    "soln_times=tf.constant(np.linspace(0.0,100.0,num=100,dtype=np.float32))\n",
    "dp = tfp.math.ode.DormandPrince()\n",
    "results = dp.solve(mod.RHS, init_time, init_state, solution_times=soln_times)\n",
    "i_true = results.states[:,0,0].numpy()\n",
    "t1 = end_day\n",
    "t2 = end_day + 7\n",
    "i_true = i_true[t1:t2]\n",
    "print(i_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "t = list(range(len(i_forecast_median)))\n",
    "plt.plot(t, i_forecast_lower, \"b--\",label = \"95-th percentile\")\n",
    "plt.plot(t, i_forecast_upper,\"b--\",label = \"5-th percentile\")\n",
    "plt.plot(t, i_forecast_median, \"b-\",label = \"Forecasted Median\")\n",
    "plt.plot(t, i_true, \"r-\", label = \"True Infected\")\n",
    "plt.title('Forecast Confidence Interval')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.savefig('Forecast.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Staircase Plot\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import staircase as sc\n",
    "inverse_data = np.column_stack((R0_sample.numpy(), nu_sample.numpy(), i_sample.numpy(), s_sample.numpy()))\n",
    "figname = \"mcmc_staircase.png\"\n",
    "ndim = 4\n",
    "scales = [0,0,0,0]\n",
    "scales[0] = (min(R0_sample),max(R0_sample))\n",
    "scales[1] = (min(nu_sample),max(nu_sample))\n",
    "scales[2] = (min(i_sample),max(i_sample))\n",
    "scales[3] = (min(s_sample),max(s_sample))\n",
    "\n",
    "bin_num = 10\n",
    "axlabel = [\"R0\", \"nu\", \"i\", \"s\"]\n",
    "#sc.staircase_plot(inverse_data, figname, hist_scalex, hist_scaley, bin_num, xtrue = [1,1,-2,-1,1])\n",
    "sc.staircase_plot_simple(inverse_data, figname, ndim, scales, bin_num, axlabel)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot MCMC evolution\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "fig, axs = plt.subplots(2, 2)\n",
    "t = list(range(len(s)))\n",
    "axs[0, 0].plot(t, R0.numpy(), \"b-\")\n",
    "axs[0, 0].set_title('R0')\n",
    "axs[0, 1].plot(t, nu.numpy(), \"b-\")\n",
    "axs[0, 1].set_title('nu')\n",
    "axs[1, 0].plot(t, i.numpy(), \"b-\")\n",
    "axs[1, 0].set_title('i')\n",
    "axs[1, 1].plot(t, s.numpy(), \"b-\")\n",
    "axs[1, 1].set_title('s')\n",
    "\n",
    "for ax in axs.flat:\n",
    "    ax.set(xlabel='MCMC draws', ylabel='Time')\n",
    "\n",
    "# Hide x labels and tick labels for top plots and y ticks for right plots.\n",
    "for ax in axs.flat:\n",
    "    ax.label_outer()\n",
    "    \n",
    "plt.savefig('MCMC_runs.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
